{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['sys', 'datetime', 'mpl']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "# import packages and libraries\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import shapefile as shp\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "import scipy.stats as stats\n",
    "import string\n",
    "from pygeocoder import Geocoder\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from IPython.display import HTML\n",
    "from shapely.geometry import Point\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from cleaned csv files - (Alt_Fuel_DW.ipynb contains the Data Wrangling code)\n",
    "alt_fuels_df = pd.read_csv('open_fuels.csv',parse_dates = True, error_bad_lines=False,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe st_df to contain ID and OpenYear for grouping stations\n",
    "st_df=alt_fuels_df[['ID','OpenDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get year from dateAdded\n",
    "def get_year(dt):\n",
    "    return dt.year\n",
    "def get_month(dt):\n",
    "    return dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>OpenDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>2010-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>1994-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>1996-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>1997-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>1996-12-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    OpenDate\n",
       "0  17  2010-12-01\n",
       "1  42  1994-07-15\n",
       "2  45  1996-12-15\n",
       "3  64  1997-01-01\n",
       "4  72  1996-12-15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = st_df.copy()\n",
    "ts_df.OpenDate= pd.to_datetime(ts_df.OpenDate)\n",
    "ts_df['Year'] = ts_df.OpenDate.map(get_year)\n",
    "ts_df['Month'] = ts_df.OpenDate.map(get_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ts_df['OpenDate']\n",
    "st_cnt_year_month = ts_df.groupby(['Year','Month']).ID.agg('count').to_frame('Count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_cnt_year_month = st_cnt_year_month[(st_cnt_year_month.Year>=2000) & (st_cnt_year_month.Year!=2019)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Month  Count\n",
       "306  2018      8     71\n",
       "307  2018      9    136\n",
       "308  2018     10    202\n",
       "309  2018     11   1031\n",
       "310  2018     12    161"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_cnt_year_month.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Count</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2000-1-01</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2000-3-01</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2000-4-01</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2000-6-01</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2000-7-01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year  Month  Count Day\n",
       "91  2000-1-01      1      7  01\n",
       "92  2000-3-01      3     19  01\n",
       "93  2000-4-01      4      4  01\n",
       "94  2000-6-01      6      3  01\n",
       "95  2000-7-01      7      1  01"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_cnt_year_month['Day']='01'\n",
    "st_cnt_year_month['Year'] = st_cnt_year_month['Year'].astype(str)+'-'+st_cnt_year_month['Month'].astype(str)+\\\n",
    "'-'+st_cnt_year_month['Day'].astype(str)\n",
    "st_cnt_year_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2018-8-01</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2018-9-01</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Year  Count\n",
       "306   2018-8-01     71\n",
       "307   2018-9-01    136\n",
       "308  2018-10-01    202\n",
       "309  2018-11-01   1031\n",
       "310  2018-12-01    161"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del st_cnt_year_month['Month']\n",
    "del st_cnt_year_month['Day']\n",
    "st_cnt_year_month.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-01', '2000-03-01', '2000-04-01', '2000-06-01',\n",
       "               '2000-07-01', '2000-08-01', '2000-10-01', '2000-11-01',\n",
       "               '2000-12-01', '2001-01-01',\n",
       "               ...\n",
       "               '2018-03-01', '2018-04-01', '2018-05-01', '2018-06-01',\n",
       "               '2018-07-01', '2018-08-01', '2018-09-01', '2018-10-01',\n",
       "               '2018-11-01', '2018-12-01'],\n",
       "              dtype='datetime64[ns]', name='Year', length=220, freq=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_cnt_year_month.Year= pd.to_datetime(st_cnt_year_month.Year)\n",
    "st_cnt_year_month.set_index('Year', inplace=True)\n",
    "st_cnt_year_month.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = st_cnt_year_month.Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "2018-08-01      71\n",
       "2018-09-01     136\n",
       "2018-10-01     202\n",
       "2018-11-01    1031\n",
       "2018-12-01     161\n",
       "Name: Count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2d383a20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Test Setup\n",
    "We will split the alternative fuels dataset into two parts: a training and a test set.\n",
    "66% of data will be taken for the training dataset and the remaining 34% of data will be used for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X = series.values\n",
    "train_size = int(len(X) * 0.66)\n",
    "train, test = X[1:train_size], X[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models will be developed using the training dataset and will make predictions on the test dataset.\n",
    "\n",
    "A rolling forecast scenario will be used, also called walk-forward model validation.\n",
    "\n",
    "Each time step of the test dataset will be walked one at a time. A model will be used to make a forecast for the time step, then the actual expected value from the test set will be taken and made available to the model for the forecast on the next time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence Forecast of Observed vs Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 177.989\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "    # make prediction\n",
    "    predictions.append(history[-1])\n",
    "    # observation\n",
    "    history.append(test[i])\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(test, predictions))\n",
    "print('RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(test)\n",
    "pyplot.plot(predictions)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Time Series to Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM model in Keras assumes that your data is divided into input (X) and output (y) components.\n",
    "\n",
    "For a time series problem, we can achieve this by using the observation from the last time step (t-1) as the input and the observation at the current time step (t) as the output.\n",
    "\n",
    "We can achieve this using the shift() function in Pandas that will push all values in a series down by a specified number places. We require a shift of 1 place, which will become the input variables. The time series as it stands will be the output variables.\n",
    "\n",
    "We can then concatenate these two series together to create a DataFrame ready for supervised learning. The pushed-down series will have a new position at the top with no value. A NaN (not a number) value will be used in this position. We will replace these NaN values with 0 values.\n",
    "\n",
    "The code below defines a helper function to do this called timeseries_to_supervised(). It takes a NumPy array of the raw time series data and a lag or number of shifted series to create and use as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this function with our loaded alternative fuel stations dataset and convert it into a supervised learning problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   0\n",
      "0   0.0   7\n",
      "1   7.0  19\n",
      "2  19.0   4\n",
      "3   4.0   3\n",
      "4   3.0   1\n"
     ]
    }
   ],
   "source": [
    "supervised = timeseries_to_supervised(X, 1)\n",
    "print(supervised.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Time Series to Stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alternative fuel stations dataset is not stationary.\n",
    "\n",
    "This means that there is a structure in the data that is dependent on the time. Specifically, there is an increasing trend in the data.\n",
    "\n",
    "Stationary data is easier to model and will very likely result in more skillful forecasts.\n",
    "\n",
    "The trend can be removed from the observations, then added back to forecasts later to return the prediction to the original scale and calculate a comparable error score.\n",
    "\n",
    "A standard way to remove a trend is by differencing the data. That is the observation from the previous time step (t-1) is subtracted from the current observation (t). This removes the trend and we are left with a difference series, or the changes to the observations from one time step to the next.\n",
    "\n",
    "We can achieve this automatically using the diff() function in pandas. Alternatively, we can get finer grained control and write our own function to do this, which is preferred for its flexibility in this case.\n",
    "\n",
    "Below is a function called difference() that calculates a differenced series. Note that the first observation in the series is skipped as there is no prior observation with which to calculate a differenced value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    " \n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    " \n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Time Series to Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like other neural networks, LSTMs expect data to be within the scale of the activation function used by the network.\n",
    "\n",
    "The default activation function for LSTMs is the hyperbolic tangent (tanh), which outputs values between -1 and 1. This is the preferred range for the time series data.\n",
    "\n",
    "To make the experiment fair, the scaling coefficients (min and max) values must be calculated on the training dataset and applied to scale the test dataset and any forecasts. This is to avoid contaminating the experiment with knowledge from the test dataset, which might give the model a small edge.\n",
    "\n",
    "We can transform the dataset to the range [-1, 1] using the MinMaxScaler class. Like other scikit-learn transform classes, it requires data provided in a matrix format with rows and columns. Therefore, we must reshape our NumPy arrays before transforming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    " \n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Long Short-Term Memory network (LSTM) is a type of Recurrent Neural Network (RNN).\n",
    "\n",
    "A benefit of this type of network is that it can learn and remember over long sequences and does not rely on a pre-specified window lagged observation as input.\n",
    "\n",
    "In Keras, this is referred to as stateful, and involves setting the stateful argument to True when defining an LSTM layer.\n",
    "\n",
    "By default, an LSTM layer in Keras maintains state between data within one batch. A batch of data is a fixed-sized number of rows from the training dataset that defines how many patterns to process before updating the weights of the network. State in the LSTM layer between batches is cleared by default, therefore we must make the LSTM stateful. This gives us fine-grained control over when state of the LSTM layer is cleared, by calling the reset_states() function.\n",
    "\n",
    "The LSTM layer expects input to be in a matrix with the dimensions: [samples, time steps, features].\n",
    "\n",
    "Samples: These are independent observations from the domain, typically rows of data.\n",
    "Time steps: These are separate time steps of a given variable for a given observation.\n",
    "Features: These are separate measures observed at the time of observation. We will keep it simple and frame the problem as each time step in the original sequence is one separate sample, with one timestep and one feature.\n",
    "\n",
    "Given that the training dataset is defined as X inputs and y outputs, it must be reshaped into the Samples/TimeSteps/Features format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model\n",
    " \n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# transform data to be stationary\n",
    "raw_values = series.values\n",
    "diff_values = difference(raw_values, 1)\n",
    " \n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test-sets\n",
    "train_size = int(len(supervised_values) * 0.66)\n",
    "train, test = supervised_values[0:train_size], supervised_values[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the LSTM model is fit to the training data, it can be used to make forecasts.\n",
    "Again, we have some flexibility. We can decide to fit the model once on all of the training data, then predict each new time step one at a time from the test data (well call this the fixed approach), or we can re-fit the model or update the model each time step of the test data as new observations from the test data are made available (well call this the dynamic approach).\n",
    "\n",
    "We will go with the fixed approach, although, we would expect the dynamic approach to result in better model skill.\n",
    "\n",
    "To make a forecast, we can call the predict() function on the model. This requires a 3D NumPy array input as an argument. In this case, it will be an array of one value, the observation at the previous time step.\n",
    "\n",
    "The predict() function returns an array of predictions, one for each input row provided. Because we are providing a single input, the output will be a 2D NumPy array with one value.\n",
    "\n",
    "We can capture this behavior in a function named forecast() listed below. Given a fit model, a batch-size used when fitting the model, and a row from the test data, the function will separate out the input data from the test row, reshape it, and return the prediction as a single floating point value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Fitting the model took 1836.3216111660004 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t=time()\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled,1,3000, 4)\n",
    "delta = time()-t\n",
    "print(f'Fitting the model took {delta} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model took 3104.329875946045 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t=time()\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled,1,1500, 1)\n",
    "delta = time()-t\n",
    "print(f'Fitting the model took {delta} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE for 1 epochs: 164.412\n",
      "Test RMSE for 2 epochs: 174.007\n",
      "Test RMSE for 4 epochs: 157.646\n",
      "Test RMSE for 8 epochs: 163.251\n",
      "Test RMSE for 16 epochs: 145.646\n",
      "Test RMSE for 32 epochs: 138.361\n",
      "Test RMSE for 64 epochs: 130.735\n",
      "Test RMSE for 128 epochs: 130.753\n",
      "Test RMSE for 256 epochs: 131.701\n",
      "Test RMSE for 512 epochs: 157.323\n",
      "Test RMSE for 1024 epochs: 165.643\n",
      "Test RMSE for 2048 epochs: 271.910\n",
      "Test RMSE for 4096 epochs: 145.216\n"
     ]
    }
   ],
   "source": [
    "# forecast the entire training dataset to build up state for forecasting\n",
    "epochs = []\n",
    "rmsel = []\n",
    "for x in range(13):\n",
    "    lstm_model = fit_lstm(train_scaled,1,2**x, 4)\n",
    "    train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "    lstm_model.predict(train_reshaped, batch_size=1) \n",
    "    \n",
    "    # walk-forward validation on the test data\n",
    "    predictions = list()\n",
    "    for i in range(len(test_scaled)):\n",
    "        # make one-step forecast\n",
    "        X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "        yhat = forecast_lstm(lstm_model, 1, X)\n",
    "        # invert scaling\n",
    "        yhat = invert_scale(scaler, X, yhat)\n",
    "        # invert differencing\n",
    "        yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "        # store forecast\n",
    "        predictions.append(yhat)\n",
    "        expected = raw_values[len(train) + i + 1]\n",
    "       \n",
    "    # report performance\n",
    "    rv = series.values\n",
    "    rvtestsize = int(len(rv) * 0.66)\n",
    "    rmse = sqrt(mean_squared_error(raw_values[rvtestsize:], predictions))\n",
    "    epochs.append(2**x)\n",
    "    rmsel.append(rmse)\n",
    "    print(f'Test RMSE for '+ str(2**x) + ' epochs: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096] [164.41188053380452, 174.00663120085414, 157.64568165594872, 163.25139361256706, 145.64556742453462, 138.36108820354767, 130.73451145794064, 130.75334936387688, 131.70122784779022, 157.3225067480201, 165.64300860737353, 271.90966810655215, 145.21556801672529]\n"
     ]
    }
   ],
   "source": [
    "print(epochs,rmsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'EPOCHS':epochs,'RMSE':rmsel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_rm_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCHS</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>164.411881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>174.006631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>157.645682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>163.251394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>145.645567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>138.361088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>130.734511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128</td>\n",
       "      <td>130.753349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>131.701228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>512</td>\n",
       "      <td>157.322507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1024</td>\n",
       "      <td>165.643009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2048</td>\n",
       "      <td>271.909668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4096</td>\n",
       "      <td>145.215568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EPOCHS        RMSE\n",
       "0        1  164.411881\n",
       "1        2  174.006631\n",
       "2        4  157.645682\n",
       "3        8  163.251394\n",
       "4       16  145.645567\n",
       "5       32  138.361088\n",
       "6       64  130.734511\n",
       "7      128  130.753349\n",
       "8      256  131.701228\n",
       "9      512  157.322507\n",
       "10    1024  165.643009\n",
       "11    2048  271.909668\n",
       "12    4096  145.215568"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_rm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(ep_rm_df.EPOCHS,ep_rm_df.RMSE)\n",
    "plt.xscale('log',basex=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each experimental scenario will be run 10 times.\n",
    "\n",
    "The reason for this is that the random initial conditions for an LSTM network can result in very different results each time a given configuration is trained.\n",
    "\n",
    "A diagnostic approach will be used to investigate model configurations. This is where line plots of model skill over time (training iterations called epochs) will be created and studied for insight into how a given configuration performs and how it may be adjusted to elicit better performance.\n",
    "\n",
    "The model will be evaluated on both the train and the test datasets at the end of each epoch and the RMSE scores saved.\n",
    "\n",
    "The train and test RMSE scores at the end of each scenario are printed to give an indication of progress.\n",
    "\n",
    "The series of train and test RMSE scores are plotted at the end of a run as a line plot. Train scores are colored blue and test scores are colored orange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "# be able to save images on server\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    " \n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised_ht(data, lag=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df = df.drop(0)\n",
    "    return df\n",
    " \n",
    "# create a differenced series\n",
    "def difference_ht(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    " \n",
    "# scale train and test data to [-1, 1]\n",
    "def scale_ht(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    " \n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale_ht(scaler, X, yhat):\n",
    "    new_row = [x for x in X] + [yhat]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]\n",
    " \n",
    "# evaluate the model on a dataset, returns RMSE in transformed units\n",
    "def evaluate_ht(model, raw_data, scaled_dataset, scaler, offset, batch_size):\n",
    "    # separate\n",
    "    X, y = scaled_dataset[:,0:-1], scaled_dataset[:,-1]\n",
    "    # reshape\n",
    "    reshaped = X.reshape(len(X), 1, 1)\n",
    "    # forecast dataset\n",
    "    output = model.predict(reshaped, batch_size=batch_size)\n",
    "    # invert data transforms on forecast\n",
    "    predictions = list()\n",
    "    for i in range(len(output)):\n",
    "        yhat = output[i,0]\n",
    "        # invert scaling\n",
    "        yhat = invert_scale_ht(scaler, X[i], yhat)\n",
    "        # invert differencing\n",
    "        yhat = yhat + raw_data[i]\n",
    "        # store forecast\n",
    "        predictions.append(yhat)\n",
    "    # report performance\n",
    "    rmse = sqrt(mean_squared_error(raw_data[1:], predictions))\n",
    "    return rmse\n",
    " \n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm_ht(train, test, raw, scaler, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    # prepare model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    # fit model\n",
    "    train_rmse, test_rmse = list(), list()\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "        # evaluate model on train data\n",
    "        raw_train = raw[-(len(train)+len(test)+1):-len(test)]\n",
    "        train_rmse.append(evaluate_ht(model, raw_train, train, scaler, 0, batch_size))\n",
    "        model.reset_states()\n",
    "        # evaluate model on test data\n",
    "        raw_test = raw[-(len(test)+1):]\n",
    "        test_rmse.append(evaluate_ht(model, raw_test, test, scaler, 0, batch_size))\n",
    "        model.reset_states()\n",
    "    history = pd.DataFrame()\n",
    "    history['train'], history['test'] = train_rmse, test_rmse\n",
    "    return history\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run diagnostic experiments\n",
    "def run(series):\n",
    "    # load dataset\n",
    "    # transform data to be stationary\n",
    "    raw_values = series.values\n",
    "    diff_values = difference_ht(raw_values, 1)\n",
    "    # transform data to be supervised learning\n",
    "    supervised = timeseries_to_supervised_ht(diff_values, 1)\n",
    "    supervised_values = supervised.values\n",
    "    # split data into train and test-sets\n",
    "    train_size = int(len(supervised_values) * 0.66)\n",
    "    train, test = supervised_values[0:train_size], supervised_values[train_size:]\n",
    "    # transform the scale of the data\n",
    "    scaler, train_scaled, test_scaled = scale_ht(train, test)\n",
    "    # fit and evaluate model\n",
    "    train_trimmed = train_scaled[2:, :]\n",
    "    # config\n",
    "    repeats = 10\n",
    "    n_batch = 1\n",
    "    n_epochs = 2\n",
    "    n_neurons = 1\n",
    "    rep=[]\n",
    "    epo=[]\n",
    "    neu=[]\n",
    "    tr_rmse=[]\n",
    "    te_rmse=[]\n",
    "    # run diagnostic tests\n",
    "    for n in range(5):\n",
    "        for e in range(13):\n",
    "            for i in range(repeats):\n",
    "                history=fit_lstm_ht(train_trimmed, test_scaled, raw_values, scaler, n_batch, n_epochs**e, n_neurons+n)\n",
    "                rep.append(i)\n",
    "                epo.append(n_epochs**e)\n",
    "                neu.append(n_neurons+n)\n",
    "                tr_rmse.append(history['train'].iloc[-1])\n",
    "                te_rmse.append(history['test'].iloc[-1])\n",
    "                pyplot.plot(history['train'], color='blue')\n",
    "                pyplot.plot(history['test'], color='orange')\n",
    "                print('%d)%d)%d) TrainRMSE=%f, TestRMSE=%f' % (n_neurons+n,n_epochs**e,i, history['train'].iloc[-1], history['test'].iloc[-1]))\n",
    "            pyplot.savefig('neurons_epochs_diagnostic_'+str(n_neurons+n)+'_'+str(n_epochs**e)+'.png')\n",
    "    hyp_dict = {'neurons':neu,'epochs':epo,'repeats':rep,'trainRMSE':tr_rmse,'testRMSE':te_rmse}\n",
    "    hyp_df = pd.DataFrame(hyp_dict)\n",
    "    return hyp_df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)1)0) TrainRMSE=117.171043, TestRMSE=181.156847\n",
      "1)1)1) TrainRMSE=107.816985, TestRMSE=167.059771\n",
      "1)1)2) TrainRMSE=139.497950, TestRMSE=214.818166\n",
      "1)1)3) TrainRMSE=112.237009, TestRMSE=173.493713\n",
      "1)1)4) TrainRMSE=105.891294, TestRMSE=163.831630\n",
      "1)1)5) TrainRMSE=118.214135, TestRMSE=183.129720\n",
      "1)1)6) TrainRMSE=114.273164, TestRMSE=176.930894\n",
      "1)1)7) TrainRMSE=111.103770, TestRMSE=172.292998\n",
      "1)1)8) TrainRMSE=112.913253, TestRMSE=174.972426\n",
      "1)1)9) TrainRMSE=121.338531, TestRMSE=187.751111\n",
      "1)2)0) TrainRMSE=118.436461, TestRMSE=183.321052\n",
      "1)2)1) TrainRMSE=122.388003, TestRMSE=186.436893\n",
      "1)2)2) TrainRMSE=120.438717, TestRMSE=186.113049\n",
      "1)2)3) TrainRMSE=130.372919, TestRMSE=201.071505\n",
      "1)2)4) TrainRMSE=121.512500, TestRMSE=187.985447\n",
      "1)2)5) TrainRMSE=116.044592, TestRMSE=179.699507\n",
      "1)2)6) TrainRMSE=106.916715, TestRMSE=164.722510\n",
      "1)2)7) TrainRMSE=109.141780, TestRMSE=168.936454\n",
      "1)2)8) TrainRMSE=119.341834, TestRMSE=184.508717\n",
      "1)2)9) TrainRMSE=114.052727, TestRMSE=176.680197\n",
      "1)4)0) TrainRMSE=106.360165, TestRMSE=164.917898\n",
      "1)4)1) TrainRMSE=109.748512, TestRMSE=169.501466\n",
      "1)4)2) TrainRMSE=116.487502, TestRMSE=180.403291\n",
      "1)4)3) TrainRMSE=105.470517, TestRMSE=163.154735\n",
      "1)4)4) TrainRMSE=114.486447, TestRMSE=177.399002\n",
      "1)4)5) TrainRMSE=121.289834, TestRMSE=187.237515\n",
      "1)4)6) TrainRMSE=117.067810, TestRMSE=181.196096\n",
      "1)4)7) TrainRMSE=117.073586, TestRMSE=181.198272\n",
      "1)4)8) TrainRMSE=116.112144, TestRMSE=179.641543\n",
      "1)4)9) TrainRMSE=115.262901, TestRMSE=178.514242\n",
      "1)8)0) TrainRMSE=111.245560, TestRMSE=172.203055\n",
      "1)8)1) TrainRMSE=116.429473, TestRMSE=180.413167\n",
      "1)8)2) TrainRMSE=103.259552, TestRMSE=160.551429\n",
      "1)8)3) TrainRMSE=102.073240, TestRMSE=159.053329\n",
      "1)8)4) TrainRMSE=115.493389, TestRMSE=178.856092\n",
      "1)8)5) TrainRMSE=114.998855, TestRMSE=178.126393\n",
      "1)8)6) TrainRMSE=113.439222, TestRMSE=175.761460\n",
      "1)8)7) TrainRMSE=112.342500, TestRMSE=173.983978\n",
      "1)8)8) TrainRMSE=106.935640, TestRMSE=166.403062\n",
      "1)8)9) TrainRMSE=110.043542, TestRMSE=169.677661\n",
      "1)16)0) TrainRMSE=98.980359, TestRMSE=154.860899\n",
      "1)16)1) TrainRMSE=111.966584, TestRMSE=173.762277\n",
      "1)16)2) TrainRMSE=115.616084, TestRMSE=179.135697\n",
      "1)16)3) TrainRMSE=109.074690, TestRMSE=168.726711\n",
      "1)16)4) TrainRMSE=119.981222, TestRMSE=185.351616\n",
      "1)16)5) TrainRMSE=121.002337, TestRMSE=186.557134\n",
      "1)16)6) TrainRMSE=118.124354, TestRMSE=182.840643\n",
      "1)16)7) TrainRMSE=101.891613, TestRMSE=155.569189\n",
      "1)16)8) TrainRMSE=111.774975, TestRMSE=173.923648\n",
      "1)16)9) TrainRMSE=115.030063, TestRMSE=178.218052\n",
      "1)32)0) TrainRMSE=101.808835, TestRMSE=154.604892\n",
      "1)32)1) TrainRMSE=95.079409, TestRMSE=140.465505\n",
      "1)32)2) TrainRMSE=82.634981, TestRMSE=129.206653\n",
      "1)32)3) TrainRMSE=116.031474, TestRMSE=160.212861\n",
      "1)32)4) TrainRMSE=114.350584, TestRMSE=177.290257\n",
      "1)32)5) TrainRMSE=94.829576, TestRMSE=147.258843\n",
      "1)32)6) TrainRMSE=114.605767, TestRMSE=177.524124\n",
      "1)32)7) TrainRMSE=113.320142, TestRMSE=160.445294\n",
      "1)32)8) TrainRMSE=109.401499, TestRMSE=170.854702\n",
      "1)32)9) TrainRMSE=114.400214, TestRMSE=162.147243\n",
      "1)64)0) TrainRMSE=82.468121, TestRMSE=135.421530\n",
      "1)64)1) TrainRMSE=91.160117, TestRMSE=132.463997\n",
      "1)64)2) TrainRMSE=94.963128, TestRMSE=144.556973\n",
      "1)64)3) TrainRMSE=102.992322, TestRMSE=161.189494\n",
      "1)64)4) TrainRMSE=102.757769, TestRMSE=161.969313\n",
      "1)64)5) TrainRMSE=88.234699, TestRMSE=135.491221\n",
      "1)64)6) TrainRMSE=113.411289, TestRMSE=175.862091\n",
      "1)64)7) TrainRMSE=80.337642, TestRMSE=132.156780\n",
      "1)64)8) TrainRMSE=95.125905, TestRMSE=146.444162\n",
      "1)64)9) TrainRMSE=106.654010, TestRMSE=166.864806\n",
      "1)128)0) TrainRMSE=97.264804, TestRMSE=148.854946\n",
      "1)128)1) TrainRMSE=92.375897, TestRMSE=150.551627\n",
      "1)128)2) TrainRMSE=87.847263, TestRMSE=131.421432\n",
      "1)128)3) TrainRMSE=81.006781, TestRMSE=128.594236\n",
      "1)128)4) TrainRMSE=98.531877, TestRMSE=156.418140\n",
      "1)128)5) TrainRMSE=96.577524, TestRMSE=152.379562\n",
      "1)128)6) TrainRMSE=78.868432, TestRMSE=139.992136\n",
      "1)128)7) TrainRMSE=87.619665, TestRMSE=135.142857\n",
      "1)128)8) TrainRMSE=94.051074, TestRMSE=152.521571\n",
      "1)128)9) TrainRMSE=95.491688, TestRMSE=155.293850\n",
      "1)256)0) TrainRMSE=82.699805, TestRMSE=142.091753\n",
      "1)256)1) TrainRMSE=77.070932, TestRMSE=140.713814\n",
      "1)256)2) TrainRMSE=76.406911, TestRMSE=138.181143\n",
      "1)256)3) TrainRMSE=94.391160, TestRMSE=148.991464\n",
      "1)256)4) TrainRMSE=77.747833, TestRMSE=132.462437\n",
      "1)256)5) TrainRMSE=77.623709, TestRMSE=134.981586\n",
      "1)256)6) TrainRMSE=76.764980, TestRMSE=142.508765\n",
      "1)256)7) TrainRMSE=79.536480, TestRMSE=136.691251\n",
      "1)256)8) TrainRMSE=76.794266, TestRMSE=147.564583\n",
      "1)256)9) TrainRMSE=78.367062, TestRMSE=136.920751\n",
      "1)512)0) TrainRMSE=75.382340, TestRMSE=141.197831\n",
      "1)512)1) TrainRMSE=76.391392, TestRMSE=144.387701\n",
      "1)512)2) TrainRMSE=72.805181, TestRMSE=140.661594\n",
      "1)512)3) TrainRMSE=94.835276, TestRMSE=148.058144\n",
      "1)512)4) TrainRMSE=77.093802, TestRMSE=148.613677\n",
      "1)512)5) TrainRMSE=82.721603, TestRMSE=137.821479\n",
      "1)512)6) TrainRMSE=94.604272, TestRMSE=147.096377\n",
      "1)512)7) TrainRMSE=76.919163, TestRMSE=141.174562\n",
      "1)512)8) TrainRMSE=82.705791, TestRMSE=146.455287\n",
      "1)512)9) TrainRMSE=94.480160, TestRMSE=147.718328\n",
      "1)1024)0) TrainRMSE=82.706575, TestRMSE=147.061413\n",
      "1)1024)1) TrainRMSE=69.850038, TestRMSE=144.448824\n",
      "1)1024)2) TrainRMSE=73.799367, TestRMSE=140.922117\n",
      "1)1024)3) TrainRMSE=76.155223, TestRMSE=141.784156\n",
      "1)1024)4) TrainRMSE=76.173333, TestRMSE=146.015413\n",
      "1)1024)5) TrainRMSE=73.074912, TestRMSE=141.962674\n",
      "1)1024)6) TrainRMSE=74.956120, TestRMSE=147.164844\n",
      "1)1024)7) TrainRMSE=70.033836, TestRMSE=144.209193\n",
      "1)1024)8) TrainRMSE=74.014670, TestRMSE=142.293938\n",
      "1)1024)9) TrainRMSE=78.184534, TestRMSE=144.444894\n",
      "1)2048)0) TrainRMSE=81.560026, TestRMSE=126.471864\n",
      "1)2048)1) TrainRMSE=70.868475, TestRMSE=150.761721\n",
      "1)2048)2) TrainRMSE=71.441235, TestRMSE=138.259510\n",
      "1)2048)3) TrainRMSE=82.602987, TestRMSE=146.823789\n",
      "1)2048)4) TrainRMSE=74.066222, TestRMSE=141.497228\n",
      "1)2048)5) TrainRMSE=70.530985, TestRMSE=143.796729\n",
      "1)2048)6) TrainRMSE=75.936719, TestRMSE=141.999739\n",
      "1)2048)7) TrainRMSE=75.018815, TestRMSE=141.419973\n",
      "1)2048)8) TrainRMSE=73.818845, TestRMSE=136.383841\n",
      "1)2048)9) TrainRMSE=73.602137, TestRMSE=137.856897\n",
      "1)4096)0) TrainRMSE=73.611431, TestRMSE=139.675567\n",
      "1)4096)1) TrainRMSE=81.701112, TestRMSE=126.865945\n",
      "1)4096)2) TrainRMSE=81.734609, TestRMSE=126.777980\n",
      "1)4096)3) TrainRMSE=81.495044, TestRMSE=126.794030\n",
      "1)4096)4) TrainRMSE=81.561133, TestRMSE=126.481712\n",
      "1)4096)5) TrainRMSE=74.407487, TestRMSE=141.631861\n",
      "1)4096)6) TrainRMSE=74.509246, TestRMSE=141.665467\n",
      "1)4096)7) TrainRMSE=81.782072, TestRMSE=127.454027\n",
      "1)4096)8) TrainRMSE=74.268567, TestRMSE=142.951718\n",
      "1)4096)9) TrainRMSE=73.750289, TestRMSE=140.056126\n",
      "2)1)0) TrainRMSE=126.702228, TestRMSE=195.796258\n",
      "2)1)1) TrainRMSE=127.851188, TestRMSE=197.685514\n",
      "2)1)2) TrainRMSE=105.577648, TestRMSE=163.660288\n",
      "2)1)3) TrainRMSE=122.657403, TestRMSE=189.671239\n",
      "2)1)4) TrainRMSE=135.728502, TestRMSE=208.851367\n",
      "2)1)5) TrainRMSE=107.369842, TestRMSE=165.336258\n",
      "2)1)6) TrainRMSE=112.325586, TestRMSE=173.385094\n",
      "2)1)7) TrainRMSE=117.621921, TestRMSE=181.779287\n",
      "2)1)8) TrainRMSE=108.481705, TestRMSE=167.726360\n",
      "2)1)9) TrainRMSE=111.997110, TestRMSE=173.464165\n",
      "2)2)0) TrainRMSE=117.997796, TestRMSE=182.685492\n",
      "2)2)1) TrainRMSE=112.779299, TestRMSE=174.794204\n",
      "2)2)2) TrainRMSE=113.189538, TestRMSE=175.347875\n",
      "2)2)3) TrainRMSE=114.400556, TestRMSE=177.184992\n",
      "2)2)4) TrainRMSE=112.087674, TestRMSE=173.579737\n",
      "2)2)5) TrainRMSE=111.504783, TestRMSE=173.238172\n",
      "2)2)6) TrainRMSE=110.075001, TestRMSE=169.774081\n",
      "2)2)7) TrainRMSE=122.293316, TestRMSE=188.909793\n",
      "2)2)8) TrainRMSE=110.524704, TestRMSE=171.347937\n",
      "2)2)9) TrainRMSE=114.116366, TestRMSE=176.645938\n",
      "2)4)0) TrainRMSE=115.477383, TestRMSE=178.907208\n",
      "2)4)1) TrainRMSE=114.901882, TestRMSE=177.750051\n",
      "2)4)2) TrainRMSE=118.788067, TestRMSE=183.772771\n",
      "2)4)3) TrainRMSE=104.462923, TestRMSE=161.975171\n",
      "2)4)4) TrainRMSE=120.882842, TestRMSE=187.156967\n",
      "2)4)5) TrainRMSE=101.763464, TestRMSE=156.288266\n",
      "2)4)6) TrainRMSE=112.941583, TestRMSE=175.131835\n",
      "2)4)7) TrainRMSE=118.508931, TestRMSE=183.425200\n",
      "2)4)8) TrainRMSE=115.909386, TestRMSE=179.361110\n",
      "2)4)9) TrainRMSE=112.571251, TestRMSE=174.488747\n",
      "2)8)0) TrainRMSE=117.171534, TestRMSE=181.070763\n",
      "2)8)1) TrainRMSE=106.645430, TestRMSE=164.630766\n",
      "2)8)2) TrainRMSE=105.329774, TestRMSE=163.279884\n",
      "2)8)3) TrainRMSE=95.360475, TestRMSE=146.144376\n",
      "2)8)4) TrainRMSE=114.712291, TestRMSE=177.706001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2)8)5) TrainRMSE=98.349321, TestRMSE=152.488365\n",
      "2)8)6) TrainRMSE=103.484568, TestRMSE=159.045458\n",
      "2)8)7) TrainRMSE=109.639771, TestRMSE=169.458416\n",
      "2)8)8) TrainRMSE=102.863624, TestRMSE=159.670546\n",
      "2)8)9) TrainRMSE=115.628856, TestRMSE=178.802204\n",
      "2)16)0) TrainRMSE=114.226275, TestRMSE=168.202454\n",
      "2)16)1) TrainRMSE=148.555403, TestRMSE=180.773739\n",
      "2)16)2) TrainRMSE=103.197721, TestRMSE=155.354915\n",
      "2)16)3) TrainRMSE=100.868237, TestRMSE=157.752289\n",
      "2)16)4) TrainRMSE=113.823144, TestRMSE=176.263776\n",
      "2)16)5) TrainRMSE=91.853232, TestRMSE=142.023922\n",
      "2)16)6) TrainRMSE=107.995437, TestRMSE=167.727563\n",
      "2)16)7) TrainRMSE=115.181597, TestRMSE=173.215045\n",
      "2)16)8) TrainRMSE=105.027948, TestRMSE=162.629260\n",
      "2)16)9) TrainRMSE=114.875652, TestRMSE=178.324657\n",
      "2)32)0) TrainRMSE=110.967994, TestRMSE=172.835949\n",
      "2)32)1) TrainRMSE=108.864035, TestRMSE=150.410107\n",
      "2)32)2) TrainRMSE=104.733667, TestRMSE=142.443531\n",
      "2)32)3) TrainRMSE=106.587674, TestRMSE=162.350635\n",
      "2)32)4) TrainRMSE=105.882256, TestRMSE=140.191881\n",
      "2)32)5) TrainRMSE=130.151921, TestRMSE=176.345554\n",
      "2)32)6) TrainRMSE=104.529227, TestRMSE=147.044424\n",
      "2)32)7) TrainRMSE=107.532305, TestRMSE=163.662900\n",
      "2)32)8) TrainRMSE=112.192189, TestRMSE=174.359526\n",
      "2)32)9) TrainRMSE=114.885654, TestRMSE=149.134379\n",
      "2)64)0) TrainRMSE=87.790474, TestRMSE=128.464670\n",
      "2)64)1) TrainRMSE=94.755400, TestRMSE=145.456592\n",
      "2)64)2) TrainRMSE=92.297713, TestRMSE=132.918002\n",
      "2)64)3) TrainRMSE=93.927459, TestRMSE=140.015620\n",
      "2)64)4) TrainRMSE=83.131090, TestRMSE=130.199795\n",
      "2)64)5) TrainRMSE=95.551126, TestRMSE=142.738554\n",
      "2)64)6) TrainRMSE=84.699594, TestRMSE=133.838951\n",
      "2)64)7) TrainRMSE=88.550343, TestRMSE=132.633742\n",
      "2)64)8) TrainRMSE=83.454147, TestRMSE=129.714045\n",
      "2)64)9) TrainRMSE=101.226627, TestRMSE=155.074607\n",
      "2)128)0) TrainRMSE=81.942226, TestRMSE=133.707763\n",
      "2)128)1) TrainRMSE=80.200112, TestRMSE=133.752529\n",
      "2)128)2) TrainRMSE=80.520753, TestRMSE=131.956187\n",
      "2)128)3) TrainRMSE=79.207001, TestRMSE=132.243309\n",
      "2)128)4) TrainRMSE=79.964779, TestRMSE=130.178364\n",
      "2)128)5) TrainRMSE=84.997068, TestRMSE=134.907726\n",
      "2)128)6) TrainRMSE=80.356102, TestRMSE=129.183994\n",
      "2)128)7) TrainRMSE=86.611274, TestRMSE=135.310657\n",
      "2)128)8) TrainRMSE=81.952108, TestRMSE=129.169488\n",
      "2)128)9) TrainRMSE=82.114845, TestRMSE=131.706519\n",
      "2)256)0) TrainRMSE=75.518581, TestRMSE=130.857882\n",
      "2)256)1) TrainRMSE=84.210671, TestRMSE=144.908675\n",
      "2)256)2) TrainRMSE=75.036200, TestRMSE=133.819206\n",
      "2)256)3) TrainRMSE=82.417455, TestRMSE=143.230817\n",
      "2)256)4) TrainRMSE=74.671647, TestRMSE=147.344949\n",
      "2)256)5) TrainRMSE=75.722492, TestRMSE=130.873753\n",
      "2)256)6) TrainRMSE=75.590041, TestRMSE=136.697357\n",
      "2)256)7) TrainRMSE=76.996747, TestRMSE=139.590977\n",
      "2)256)8) TrainRMSE=76.065783, TestRMSE=138.130715\n",
      "2)256)9) TrainRMSE=75.894125, TestRMSE=133.034787\n",
      "2)512)0) TrainRMSE=75.217929, TestRMSE=155.826735\n",
      "2)512)1) TrainRMSE=78.079157, TestRMSE=137.250537\n",
      "2)512)2) TrainRMSE=76.865941, TestRMSE=147.296577\n",
      "2)512)3) TrainRMSE=74.884945, TestRMSE=170.285986\n",
      "2)512)4) TrainRMSE=86.640653, TestRMSE=174.297269\n",
      "2)512)5) TrainRMSE=69.810149, TestRMSE=147.903288\n",
      "2)512)6) TrainRMSE=77.044692, TestRMSE=143.083412\n",
      "2)512)7) TrainRMSE=76.578126, TestRMSE=143.926751\n",
      "2)512)8) TrainRMSE=69.588796, TestRMSE=147.242227\n",
      "2)512)9) TrainRMSE=74.887698, TestRMSE=153.578508\n",
      "2)1024)0) TrainRMSE=74.067104, TestRMSE=161.258119\n",
      "2)1024)1) TrainRMSE=67.541037, TestRMSE=179.341976\n",
      "2)1024)2) TrainRMSE=68.847184, TestRMSE=147.824186\n",
      "2)1024)3) TrainRMSE=70.840585, TestRMSE=140.145439\n",
      "2)1024)4) TrainRMSE=75.387750, TestRMSE=157.712630\n",
      "2)1024)5) TrainRMSE=69.031190, TestRMSE=157.006643\n",
      "2)1024)6) TrainRMSE=69.733026, TestRMSE=168.261723\n",
      "2)1024)7) TrainRMSE=71.964672, TestRMSE=192.867848\n",
      "2)1024)8) TrainRMSE=73.832864, TestRMSE=143.053608\n",
      "2)1024)9) TrainRMSE=73.471316, TestRMSE=163.114835\n",
      "2)2048)0) TrainRMSE=72.004672, TestRMSE=141.715089\n",
      "2)2048)1) TrainRMSE=70.570286, TestRMSE=163.390318\n",
      "2)2048)2) TrainRMSE=68.276540, TestRMSE=199.074894\n",
      "2)2048)3) TrainRMSE=81.681091, TestRMSE=140.534836\n",
      "2)2048)4) TrainRMSE=74.651452, TestRMSE=143.393401\n",
      "2)2048)5) TrainRMSE=62.387513, TestRMSE=197.039956\n",
      "2)2048)6) TrainRMSE=64.399102, TestRMSE=187.228765\n",
      "2)2048)7) TrainRMSE=67.685511, TestRMSE=158.321941\n",
      "2)2048)8) TrainRMSE=73.260779, TestRMSE=151.739782\n",
      "2)2048)9) TrainRMSE=67.689476, TestRMSE=210.171830\n",
      "2)4096)0) TrainRMSE=53.517538, TestRMSE=177.933100\n",
      "2)4096)1) TrainRMSE=75.073060, TestRMSE=152.620428\n",
      "2)4096)2) TrainRMSE=92.201829, TestRMSE=147.267458\n",
      "2)4096)3) TrainRMSE=74.891987, TestRMSE=141.210956\n",
      "2)4096)4) TrainRMSE=80.923495, TestRMSE=123.714385\n",
      "2)4096)5) TrainRMSE=69.888640, TestRMSE=179.456017\n",
      "2)4096)6) TrainRMSE=70.763783, TestRMSE=185.977300\n",
      "2)4096)7) TrainRMSE=71.451108, TestRMSE=148.057812\n",
      "2)4096)8) TrainRMSE=61.623952, TestRMSE=440.334792\n",
      "2)4096)9) TrainRMSE=115.413371, TestRMSE=169.120469\n",
      "3)1)0) TrainRMSE=117.902913, TestRMSE=182.379288\n",
      "3)1)1) TrainRMSE=108.362081, TestRMSE=167.965302\n",
      "3)1)2) TrainRMSE=95.300727, TestRMSE=148.511412\n",
      "3)1)3) TrainRMSE=108.518945, TestRMSE=167.914126\n",
      "3)1)4) TrainRMSE=107.087843, TestRMSE=165.715922\n",
      "3)1)5) TrainRMSE=111.791290, TestRMSE=173.238737\n",
      "3)1)6) TrainRMSE=112.168353, TestRMSE=173.768753\n",
      "3)1)7) TrainRMSE=112.226421, TestRMSE=173.322177\n",
      "3)1)8) TrainRMSE=111.602032, TestRMSE=172.950129\n",
      "3)1)9) TrainRMSE=114.797843, TestRMSE=177.737161\n",
      "3)2)0) TrainRMSE=123.889366, TestRMSE=191.683923\n",
      "3)2)1) TrainRMSE=117.366909, TestRMSE=181.791358\n",
      "3)2)2) TrainRMSE=121.657898, TestRMSE=188.118303\n",
      "3)2)3) TrainRMSE=104.149213, TestRMSE=160.113187\n",
      "3)2)4) TrainRMSE=115.630104, TestRMSE=179.089649\n",
      "3)2)5) TrainRMSE=109.006820, TestRMSE=169.144926\n",
      "3)2)6) TrainRMSE=100.609753, TestRMSE=155.378912\n",
      "3)2)7) TrainRMSE=110.904213, TestRMSE=171.865311\n",
      "3)2)8) TrainRMSE=112.012086, TestRMSE=173.132207\n",
      "3)2)9) TrainRMSE=110.196878, TestRMSE=170.770619\n",
      "3)4)0) TrainRMSE=106.152834, TestRMSE=163.377267\n",
      "3)4)1) TrainRMSE=98.310624, TestRMSE=152.695834\n",
      "3)4)2) TrainRMSE=99.359416, TestRMSE=154.760128\n",
      "3)4)3) TrainRMSE=110.642371, TestRMSE=171.507455\n",
      "3)4)4) TrainRMSE=111.521876, TestRMSE=172.399339\n",
      "3)4)5) TrainRMSE=108.853116, TestRMSE=168.750291\n",
      "3)4)6) TrainRMSE=105.872478, TestRMSE=164.063101\n",
      "3)4)7) TrainRMSE=120.558891, TestRMSE=186.341400\n",
      "3)4)8) TrainRMSE=112.546141, TestRMSE=174.682286\n",
      "3)4)9) TrainRMSE=107.147904, TestRMSE=165.600143\n",
      "3)8)0) TrainRMSE=107.829279, TestRMSE=161.202293\n",
      "3)8)1) TrainRMSE=104.558478, TestRMSE=161.246487\n",
      "3)8)2) TrainRMSE=109.944479, TestRMSE=170.218723\n",
      "3)8)3) TrainRMSE=116.070379, TestRMSE=179.445976\n",
      "3)8)4) TrainRMSE=114.255109, TestRMSE=176.834959\n",
      "3)8)5) TrainRMSE=103.893146, TestRMSE=159.788493\n",
      "3)8)6) TrainRMSE=110.233909, TestRMSE=170.694165\n",
      "3)8)7) TrainRMSE=108.361072, TestRMSE=147.718071\n",
      "3)8)8) TrainRMSE=114.962723, TestRMSE=177.842704\n",
      "3)8)9) TrainRMSE=104.246500, TestRMSE=160.473635\n",
      "3)16)0) TrainRMSE=105.614489, TestRMSE=163.069146\n",
      "3)16)1) TrainRMSE=99.938206, TestRMSE=153.581261\n",
      "3)16)2) TrainRMSE=113.306878, TestRMSE=175.729864\n",
      "3)16)3) TrainRMSE=101.232405, TestRMSE=155.512123\n",
      "3)16)4) TrainRMSE=97.502779, TestRMSE=149.146654\n",
      "3)16)5) TrainRMSE=89.083459, TestRMSE=132.790030\n",
      "3)16)6) TrainRMSE=108.815964, TestRMSE=153.690424\n",
      "3)16)7) TrainRMSE=115.225991, TestRMSE=178.154830\n",
      "3)16)8) TrainRMSE=107.944005, TestRMSE=164.656554\n",
      "3)16)9) TrainRMSE=106.795876, TestRMSE=159.459278\n",
      "3)32)0) TrainRMSE=96.530510, TestRMSE=146.075107\n",
      "3)32)1) TrainRMSE=97.318596, TestRMSE=141.960521\n",
      "3)32)2) TrainRMSE=103.352522, TestRMSE=142.825896\n",
      "3)32)3) TrainRMSE=453.104056, TestRMSE=195.649092\n",
      "3)32)4) TrainRMSE=91.721541, TestRMSE=133.979570\n",
      "3)32)5) TrainRMSE=113.966088, TestRMSE=160.645028\n",
      "3)32)6) TrainRMSE=115.802767, TestRMSE=160.516863\n",
      "3)32)7) TrainRMSE=103.402050, TestRMSE=144.853966\n",
      "3)32)8) TrainRMSE=101.956964, TestRMSE=135.038071\n",
      "3)32)9) TrainRMSE=96.901395, TestRMSE=141.704051\n",
      "3)64)0) TrainRMSE=83.029861, TestRMSE=133.159959\n",
      "3)64)1) TrainRMSE=83.555785, TestRMSE=129.537910\n",
      "3)64)2) TrainRMSE=83.661093, TestRMSE=130.926241\n",
      "3)64)3) TrainRMSE=86.722144, TestRMSE=132.005940\n",
      "3)64)4) TrainRMSE=83.543628, TestRMSE=133.067285\n",
      "3)64)5) TrainRMSE=96.169663, TestRMSE=143.701270\n",
      "3)64)6) TrainRMSE=89.783451, TestRMSE=130.366386\n",
      "3)64)7) TrainRMSE=89.926455, TestRMSE=131.502403\n",
      "3)64)8) TrainRMSE=90.300200, TestRMSE=132.738323\n",
      "3)64)9) TrainRMSE=82.875579, TestRMSE=129.912519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3)128)0) TrainRMSE=86.184291, TestRMSE=132.520463\n",
      "3)128)1) TrainRMSE=77.546970, TestRMSE=136.542680\n",
      "3)128)2) TrainRMSE=87.516765, TestRMSE=136.540495\n",
      "3)128)3) TrainRMSE=79.585380, TestRMSE=131.537302\n",
      "3)128)4) TrainRMSE=82.628774, TestRMSE=129.434560\n",
      "3)128)5) TrainRMSE=77.936332, TestRMSE=135.339734\n",
      "3)128)6) TrainRMSE=79.311114, TestRMSE=134.232229\n",
      "3)128)7) TrainRMSE=84.983080, TestRMSE=131.299927\n",
      "3)128)8) TrainRMSE=84.118612, TestRMSE=131.632945\n",
      "3)128)9) TrainRMSE=78.360039, TestRMSE=133.266013\n",
      "3)256)0) TrainRMSE=77.272308, TestRMSE=133.588422\n",
      "3)256)1) TrainRMSE=76.932644, TestRMSE=155.323571\n",
      "3)256)2) TrainRMSE=81.540524, TestRMSE=136.955694\n",
      "3)256)3) TrainRMSE=75.074765, TestRMSE=140.617097\n",
      "3)256)4) TrainRMSE=76.580498, TestRMSE=143.641691\n",
      "3)256)5) TrainRMSE=75.191967, TestRMSE=142.424808\n",
      "3)256)6) TrainRMSE=80.080485, TestRMSE=128.200598\n",
      "3)256)7) TrainRMSE=79.326618, TestRMSE=125.360211\n",
      "3)256)8) TrainRMSE=74.475305, TestRMSE=155.436607\n",
      "3)256)9) TrainRMSE=76.273366, TestRMSE=137.418393\n",
      "3)512)0) TrainRMSE=69.833570, TestRMSE=166.242055\n",
      "3)512)1) TrainRMSE=74.579084, TestRMSE=160.485272\n",
      "3)512)2) TrainRMSE=77.418341, TestRMSE=147.447856\n",
      "3)512)3) TrainRMSE=74.935058, TestRMSE=158.985874\n",
      "3)512)4) TrainRMSE=78.281646, TestRMSE=145.057440\n",
      "3)512)5) TrainRMSE=73.542228, TestRMSE=167.561936\n",
      "3)512)6) TrainRMSE=76.712067, TestRMSE=153.544371\n",
      "3)512)7) TrainRMSE=73.718805, TestRMSE=152.298317\n",
      "3)512)8) TrainRMSE=76.595885, TestRMSE=156.914552\n",
      "3)512)9) TrainRMSE=71.775906, TestRMSE=151.881473\n",
      "3)1024)0) TrainRMSE=68.361855, TestRMSE=180.198759\n",
      "3)1024)1) TrainRMSE=72.078855, TestRMSE=147.963151\n",
      "3)1024)2) TrainRMSE=73.756111, TestRMSE=175.251380\n",
      "3)1024)3) TrainRMSE=78.319196, TestRMSE=148.143802\n",
      "3)1024)4) TrainRMSE=75.310950, TestRMSE=191.218329\n",
      "3)1024)5) TrainRMSE=68.338924, TestRMSE=154.620926\n",
      "3)1024)6) TrainRMSE=71.619085, TestRMSE=134.490801\n",
      "3)1024)7) TrainRMSE=70.121250, TestRMSE=179.607313\n",
      "3)1024)8) TrainRMSE=69.897751, TestRMSE=149.370036\n",
      "3)1024)9) TrainRMSE=72.611102, TestRMSE=175.985074\n",
      "3)2048)0) TrainRMSE=70.808315, TestRMSE=144.922516\n",
      "3)2048)1) TrainRMSE=69.136109, TestRMSE=138.219149\n",
      "3)2048)2) TrainRMSE=67.783679, TestRMSE=202.473821\n",
      "3)2048)3) TrainRMSE=73.616735, TestRMSE=151.308916\n",
      "3)2048)4) TrainRMSE=64.753023, TestRMSE=180.780427\n",
      "3)2048)5) TrainRMSE=69.364979, TestRMSE=267.286157\n",
      "3)2048)6) TrainRMSE=68.183642, TestRMSE=203.182611\n",
      "3)2048)7) TrainRMSE=69.594865, TestRMSE=188.305701\n",
      "3)2048)8) TrainRMSE=68.194991, TestRMSE=216.336220\n",
      "3)2048)9) TrainRMSE=83.933378, TestRMSE=154.192729\n",
      "3)4096)0) TrainRMSE=75.027719, TestRMSE=191.193865\n",
      "3)4096)1) TrainRMSE=82.252409, TestRMSE=127.475636\n",
      "3)4096)2) TrainRMSE=84.718563, TestRMSE=142.747724\n",
      "3)4096)3) TrainRMSE=72.688481, TestRMSE=137.523207\n",
      "3)4096)4) TrainRMSE=59.786852, TestRMSE=622.907872\n",
      "3)4096)5) TrainRMSE=75.041166, TestRMSE=155.217122\n",
      "3)4096)6) TrainRMSE=59.419143, TestRMSE=375.668832\n",
      "3)4096)7) TrainRMSE=75.118176, TestRMSE=146.032603\n",
      "3)4096)8) TrainRMSE=61.021736, TestRMSE=283.499114\n",
      "3)4096)9) TrainRMSE=95.631355, TestRMSE=150.396807\n",
      "4)1)0) TrainRMSE=105.253203, TestRMSE=162.484917\n",
      "4)1)1) TrainRMSE=114.447373, TestRMSE=177.164874\n",
      "4)1)2) TrainRMSE=118.564695, TestRMSE=183.420156\n",
      "4)1)3) TrainRMSE=111.507197, TestRMSE=172.757057\n",
      "4)1)4) TrainRMSE=109.608084, TestRMSE=169.874295\n",
      "4)1)5) TrainRMSE=117.139112, TestRMSE=181.177788\n",
      "4)1)6) TrainRMSE=104.502965, TestRMSE=162.108968\n",
      "4)1)7) TrainRMSE=114.173142, TestRMSE=176.949975\n",
      "4)1)8) TrainRMSE=129.343322, TestRMSE=200.035972\n",
      "4)1)9) TrainRMSE=112.509247, TestRMSE=174.279949\n",
      "4)2)0) TrainRMSE=110.872068, TestRMSE=172.025605\n",
      "4)2)1) TrainRMSE=118.211916, TestRMSE=182.822364\n",
      "4)2)2) TrainRMSE=114.466852, TestRMSE=177.295910\n",
      "4)2)3) TrainRMSE=114.187339, TestRMSE=176.855415\n",
      "4)2)4) TrainRMSE=102.836480, TestRMSE=159.281047\n",
      "4)2)5) TrainRMSE=111.100938, TestRMSE=172.048066\n",
      "4)2)6) TrainRMSE=127.877109, TestRMSE=197.301521\n",
      "4)2)7) TrainRMSE=118.533443, TestRMSE=183.631816\n",
      "4)2)8) TrainRMSE=111.453038, TestRMSE=172.469595\n",
      "4)2)9) TrainRMSE=108.628312, TestRMSE=168.092125\n",
      "4)4)0) TrainRMSE=113.638273, TestRMSE=176.041234\n",
      "4)4)1) TrainRMSE=100.129536, TestRMSE=154.438985\n",
      "4)4)2) TrainRMSE=114.866768, TestRMSE=177.663302\n",
      "4)4)3) TrainRMSE=117.538311, TestRMSE=181.908068\n",
      "4)4)4) TrainRMSE=108.631629, TestRMSE=167.940183\n",
      "4)4)5) TrainRMSE=104.923814, TestRMSE=162.602730\n",
      "4)4)6) TrainRMSE=115.612227, TestRMSE=179.072581\n",
      "4)4)7) TrainRMSE=123.979436, TestRMSE=191.279324\n",
      "4)4)8) TrainRMSE=109.804307, TestRMSE=170.150904\n",
      "4)4)9) TrainRMSE=104.347859, TestRMSE=159.948290\n",
      "4)8)0) TrainRMSE=99.437106, TestRMSE=153.601333\n",
      "4)8)1) TrainRMSE=97.198922, TestRMSE=149.625406\n",
      "4)8)2) TrainRMSE=111.010175, TestRMSE=171.218050\n",
      "4)8)3) TrainRMSE=109.906309, TestRMSE=170.183444\n",
      "4)8)4) TrainRMSE=92.407526, TestRMSE=141.694669\n",
      "4)8)5) TrainRMSE=103.515388, TestRMSE=153.303356\n",
      "4)8)6) TrainRMSE=92.877246, TestRMSE=143.593319\n",
      "4)8)7) TrainRMSE=118.672318, TestRMSE=183.689964\n",
      "4)8)8) TrainRMSE=104.100914, TestRMSE=160.884748\n",
      "4)8)9) TrainRMSE=103.936599, TestRMSE=160.070880\n",
      "4)16)0) TrainRMSE=115.220028, TestRMSE=159.526852\n",
      "4)16)1) TrainRMSE=106.431355, TestRMSE=165.009747\n",
      "4)16)2) TrainRMSE=103.328393, TestRMSE=146.640135\n",
      "4)16)3) TrainRMSE=112.258902, TestRMSE=173.742852\n",
      "4)16)4) TrainRMSE=100.478551, TestRMSE=149.047162\n",
      "4)16)5) TrainRMSE=105.581249, TestRMSE=162.845115\n",
      "4)16)6) TrainRMSE=101.027275, TestRMSE=147.270627\n",
      "4)16)7) TrainRMSE=115.739447, TestRMSE=158.563496\n",
      "4)16)8) TrainRMSE=105.263844, TestRMSE=153.103414\n",
      "4)16)9) TrainRMSE=110.098694, TestRMSE=147.768432\n",
      "4)32)0) TrainRMSE=106.312273, TestRMSE=152.515499\n",
      "4)32)1) TrainRMSE=91.935707, TestRMSE=134.605332\n",
      "4)32)2) TrainRMSE=100.654014, TestRMSE=143.345345\n",
      "4)32)3) TrainRMSE=88.638087, TestRMSE=130.078275\n",
      "4)32)4) TrainRMSE=94.449061, TestRMSE=133.228444\n",
      "4)32)5) TrainRMSE=125.973510, TestRMSE=168.085496\n",
      "4)32)6) TrainRMSE=100.575404, TestRMSE=138.994897\n",
      "4)32)7) TrainRMSE=99.639561, TestRMSE=135.070862\n",
      "4)32)8) TrainRMSE=109.864608, TestRMSE=159.982221\n",
      "4)32)9) TrainRMSE=101.944362, TestRMSE=151.837843\n",
      "4)64)0) TrainRMSE=83.323390, TestRMSE=131.562901\n",
      "4)64)1) TrainRMSE=87.100596, TestRMSE=132.980957\n",
      "4)64)2) TrainRMSE=84.332602, TestRMSE=129.661396\n",
      "4)64)3) TrainRMSE=84.820366, TestRMSE=132.303495\n",
      "4)64)4) TrainRMSE=82.788360, TestRMSE=128.774751\n",
      "4)64)5) TrainRMSE=83.868011, TestRMSE=129.987317\n",
      "4)64)6) TrainRMSE=85.010316, TestRMSE=130.659896\n",
      "4)64)7) TrainRMSE=84.878463, TestRMSE=130.434216\n",
      "4)64)8) TrainRMSE=83.546259, TestRMSE=130.901873\n",
      "4)64)9) TrainRMSE=89.533602, TestRMSE=137.546750\n",
      "4)128)0) TrainRMSE=79.385313, TestRMSE=130.128336\n",
      "4)128)1) TrainRMSE=79.157739, TestRMSE=132.789095\n",
      "4)128)2) TrainRMSE=82.912815, TestRMSE=128.878896\n",
      "4)128)3) TrainRMSE=79.342774, TestRMSE=129.657023\n",
      "4)128)4) TrainRMSE=83.620609, TestRMSE=127.572338\n",
      "4)128)5) TrainRMSE=77.605434, TestRMSE=134.391052\n",
      "4)128)6) TrainRMSE=83.877159, TestRMSE=129.000869\n",
      "4)128)7) TrainRMSE=81.376891, TestRMSE=127.719312\n",
      "4)128)8) TrainRMSE=78.424532, TestRMSE=131.168680\n",
      "4)128)9) TrainRMSE=78.799395, TestRMSE=129.665735\n",
      "4)256)0) TrainRMSE=71.294399, TestRMSE=136.890787\n",
      "4)256)1) TrainRMSE=79.353575, TestRMSE=144.901208\n",
      "4)256)2) TrainRMSE=73.414915, TestRMSE=142.098698\n",
      "4)256)3) TrainRMSE=76.158169, TestRMSE=142.923773\n",
      "4)256)4) TrainRMSE=76.791607, TestRMSE=139.786295\n",
      "4)256)5) TrainRMSE=76.945364, TestRMSE=144.562433\n",
      "4)256)6) TrainRMSE=74.101288, TestRMSE=130.141824\n",
      "4)256)7) TrainRMSE=77.025329, TestRMSE=130.777277\n",
      "4)256)8) TrainRMSE=75.225733, TestRMSE=142.771387\n",
      "4)256)9) TrainRMSE=75.717402, TestRMSE=138.478762\n",
      "4)512)0) TrainRMSE=74.867679, TestRMSE=152.565511\n",
      "4)512)1) TrainRMSE=72.526361, TestRMSE=140.727017\n",
      "4)512)2) TrainRMSE=74.569093, TestRMSE=153.908415\n",
      "4)512)3) TrainRMSE=78.409105, TestRMSE=170.631823\n",
      "4)512)4) TrainRMSE=75.339525, TestRMSE=150.787513\n",
      "4)512)5) TrainRMSE=75.444577, TestRMSE=159.241076\n",
      "4)512)6) TrainRMSE=72.257018, TestRMSE=152.638295\n",
      "4)512)7) TrainRMSE=78.785086, TestRMSE=187.129001\n",
      "4)512)8) TrainRMSE=128.007439, TestRMSE=176.097038\n",
      "4)512)9) TrainRMSE=73.021621, TestRMSE=150.245346\n",
      "4)1024)0) TrainRMSE=73.790416, TestRMSE=139.443746\n",
      "4)1024)1) TrainRMSE=72.419416, TestRMSE=189.789658\n",
      "4)1024)2) TrainRMSE=68.426376, TestRMSE=179.185756\n",
      "4)1024)3) TrainRMSE=73.877236, TestRMSE=140.159214\n",
      "4)1024)4) TrainRMSE=91.067779, TestRMSE=182.024656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4)1024)5) TrainRMSE=85.420349, TestRMSE=178.055331\n",
      "4)1024)6) TrainRMSE=78.951056, TestRMSE=140.739826\n",
      "4)1024)7) TrainRMSE=72.322175, TestRMSE=171.896565\n",
      "4)1024)8) TrainRMSE=65.669651, TestRMSE=184.544874\n",
      "4)1024)9) TrainRMSE=72.930849, TestRMSE=159.913905\n",
      "4)2048)0) TrainRMSE=76.634591, TestRMSE=198.053919\n",
      "4)2048)1) TrainRMSE=66.573304, TestRMSE=176.188640\n",
      "4)2048)2) TrainRMSE=74.538882, TestRMSE=209.034153\n",
      "4)2048)3) TrainRMSE=68.334159, TestRMSE=212.902527\n",
      "4)2048)4) TrainRMSE=76.936187, TestRMSE=141.608376\n",
      "4)2048)5) TrainRMSE=66.163522, TestRMSE=195.117923\n",
      "4)2048)6) TrainRMSE=76.900664, TestRMSE=192.754898\n",
      "4)2048)7) TrainRMSE=75.210534, TestRMSE=145.405889\n",
      "4)2048)8) TrainRMSE=74.855862, TestRMSE=201.738670\n",
      "4)2048)9) TrainRMSE=71.435101, TestRMSE=148.911267\n",
      "4)4096)0) TrainRMSE=56.430997, TestRMSE=178.479596\n",
      "4)4096)1) TrainRMSE=72.237204, TestRMSE=171.512765\n",
      "4)4096)2) TrainRMSE=68.648390, TestRMSE=222.253637\n",
      "4)4096)3) TrainRMSE=74.003312, TestRMSE=162.037699\n",
      "4)4096)4) TrainRMSE=54.154849, TestRMSE=133.927632\n",
      "4)4096)5) TrainRMSE=75.366283, TestRMSE=166.445264\n",
      "4)4096)6) TrainRMSE=68.178397, TestRMSE=174.606236\n",
      "4)4096)7) TrainRMSE=68.668188, TestRMSE=267.964005\n",
      "4)4096)8) TrainRMSE=98.105806, TestRMSE=173.558319\n",
      "4)4096)9) TrainRMSE=73.538555, TestRMSE=287.391182\n"
     ]
    }
   ],
   "source": [
    "# entry point\n",
    "hyperparameter_df = run(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>epochs</th>\n",
       "      <th>repeats</th>\n",
       "      <th>trainRMSE</th>\n",
       "      <th>testRMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117.171043</td>\n",
       "      <td>181.156847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>107.816985</td>\n",
       "      <td>167.059771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>139.497950</td>\n",
       "      <td>214.818166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>112.237009</td>\n",
       "      <td>173.493713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>105.891294</td>\n",
       "      <td>163.831630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>118.214135</td>\n",
       "      <td>183.129720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>114.273164</td>\n",
       "      <td>176.930894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>111.103770</td>\n",
       "      <td>172.292998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>112.913253</td>\n",
       "      <td>174.972426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>121.338531</td>\n",
       "      <td>187.751111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>118.436461</td>\n",
       "      <td>183.321052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>122.388003</td>\n",
       "      <td>186.436893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>120.438717</td>\n",
       "      <td>186.113049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>130.372919</td>\n",
       "      <td>201.071505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>121.512500</td>\n",
       "      <td>187.985447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>116.044592</td>\n",
       "      <td>179.699507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>106.916715</td>\n",
       "      <td>164.722510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>109.141780</td>\n",
       "      <td>168.936454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>119.341834</td>\n",
       "      <td>184.508717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>114.052727</td>\n",
       "      <td>176.680197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>106.360165</td>\n",
       "      <td>164.917898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>109.748512</td>\n",
       "      <td>169.501466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>116.487502</td>\n",
       "      <td>180.403291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>105.470517</td>\n",
       "      <td>163.154735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>114.486447</td>\n",
       "      <td>177.399002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>121.289834</td>\n",
       "      <td>187.237515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>117.067810</td>\n",
       "      <td>181.196096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>117.073586</td>\n",
       "      <td>181.198272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>116.112144</td>\n",
       "      <td>179.641543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>115.262901</td>\n",
       "      <td>178.514242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>0</td>\n",
       "      <td>64.823889</td>\n",
       "      <td>170.856790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>76.725783</td>\n",
       "      <td>153.638761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>69.165127</td>\n",
       "      <td>151.045093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>68.994233</td>\n",
       "      <td>197.469922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>4</td>\n",
       "      <td>73.847492</td>\n",
       "      <td>144.498775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>5</td>\n",
       "      <td>79.254162</td>\n",
       "      <td>155.862901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>6</td>\n",
       "      <td>80.832213</td>\n",
       "      <td>136.122780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>7</td>\n",
       "      <td>70.982397</td>\n",
       "      <td>189.653043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>8</td>\n",
       "      <td>76.160897</td>\n",
       "      <td>150.039746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>9</td>\n",
       "      <td>75.922385</td>\n",
       "      <td>151.184696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>5</td>\n",
       "      <td>2048</td>\n",
       "      <td>0</td>\n",
       "      <td>70.486953</td>\n",
       "      <td>195.509043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>5</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>84.951963</td>\n",
       "      <td>171.638084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>5</td>\n",
       "      <td>2048</td>\n",
       "      <td>2</td>\n",
       "      <td>62.923535</td>\n",
       "      <td>197.256679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>5</td>\n",
       "      <td>2048</td>\n",
       "      <td>3</td>\n",
       "      <td>72.110641</td>\n",
       "      <td>159.176387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>5</td>\n",
       "      <td>2048</td>\n",
       "      <td>4</td>\n",
       "      <td>61.400749</td>\n",
       "      <td>224.559143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>5</td>\n",
       "      <td>2048</td>\n",
       "      <td>5</td>\n",
       "      <td>100.450655</td>\n",
       "      <td>267.278314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>5</td>\n",
       "      <td>2048</td>\n",
       "      <td>6</td>\n",
       "      <td>83.274270</td>\n",
       "      <td>149.430076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>5</td>\n",
       "      <td>2048</td>\n",
       "      <td>7</td>\n",
       "      <td>76.937329</td>\n",
       "      <td>372.751855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>5</td>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>72.540466</td>\n",
       "      <td>159.192980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>5</td>\n",
       "      <td>2048</td>\n",
       "      <td>9</td>\n",
       "      <td>85.574427</td>\n",
       "      <td>282.483434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>5</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>75.242122</td>\n",
       "      <td>126.993030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>5</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "      <td>65.811064</td>\n",
       "      <td>182.392661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>5</td>\n",
       "      <td>4096</td>\n",
       "      <td>2</td>\n",
       "      <td>107.916359</td>\n",
       "      <td>157.715097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>5</td>\n",
       "      <td>4096</td>\n",
       "      <td>3</td>\n",
       "      <td>55.902081</td>\n",
       "      <td>172.543293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>5</td>\n",
       "      <td>4096</td>\n",
       "      <td>4</td>\n",
       "      <td>75.237736</td>\n",
       "      <td>157.737794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>5</td>\n",
       "      <td>4096</td>\n",
       "      <td>5</td>\n",
       "      <td>68.440209</td>\n",
       "      <td>158.673893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>5</td>\n",
       "      <td>4096</td>\n",
       "      <td>6</td>\n",
       "      <td>89.811060</td>\n",
       "      <td>232.169025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>5</td>\n",
       "      <td>4096</td>\n",
       "      <td>7</td>\n",
       "      <td>70.876083</td>\n",
       "      <td>156.186867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>5</td>\n",
       "      <td>4096</td>\n",
       "      <td>8</td>\n",
       "      <td>76.415816</td>\n",
       "      <td>145.934886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>5</td>\n",
       "      <td>4096</td>\n",
       "      <td>9</td>\n",
       "      <td>85.283866</td>\n",
       "      <td>141.986165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     neurons  epochs  repeats   trainRMSE    testRMSE\n",
       "0          1       1        0  117.171043  181.156847\n",
       "1          1       1        1  107.816985  167.059771\n",
       "2          1       1        2  139.497950  214.818166\n",
       "3          1       1        3  112.237009  173.493713\n",
       "4          1       1        4  105.891294  163.831630\n",
       "5          1       1        5  118.214135  183.129720\n",
       "6          1       1        6  114.273164  176.930894\n",
       "7          1       1        7  111.103770  172.292998\n",
       "8          1       1        8  112.913253  174.972426\n",
       "9          1       1        9  121.338531  187.751111\n",
       "10         1       2        0  118.436461  183.321052\n",
       "11         1       2        1  122.388003  186.436893\n",
       "12         1       2        2  120.438717  186.113049\n",
       "13         1       2        3  130.372919  201.071505\n",
       "14         1       2        4  121.512500  187.985447\n",
       "15         1       2        5  116.044592  179.699507\n",
       "16         1       2        6  106.916715  164.722510\n",
       "17         1       2        7  109.141780  168.936454\n",
       "18         1       2        8  119.341834  184.508717\n",
       "19         1       2        9  114.052727  176.680197\n",
       "20         1       4        0  106.360165  164.917898\n",
       "21         1       4        1  109.748512  169.501466\n",
       "22         1       4        2  116.487502  180.403291\n",
       "23         1       4        3  105.470517  163.154735\n",
       "24         1       4        4  114.486447  177.399002\n",
       "25         1       4        5  121.289834  187.237515\n",
       "26         1       4        6  117.067810  181.196096\n",
       "27         1       4        7  117.073586  181.198272\n",
       "28         1       4        8  116.112144  179.641543\n",
       "29         1       4        9  115.262901  178.514242\n",
       "..       ...     ...      ...         ...         ...\n",
       "620        5    1024        0   64.823889  170.856790\n",
       "621        5    1024        1   76.725783  153.638761\n",
       "622        5    1024        2   69.165127  151.045093\n",
       "623        5    1024        3   68.994233  197.469922\n",
       "624        5    1024        4   73.847492  144.498775\n",
       "625        5    1024        5   79.254162  155.862901\n",
       "626        5    1024        6   80.832213  136.122780\n",
       "627        5    1024        7   70.982397  189.653043\n",
       "628        5    1024        8   76.160897  150.039746\n",
       "629        5    1024        9   75.922385  151.184696\n",
       "630        5    2048        0   70.486953  195.509043\n",
       "631        5    2048        1   84.951963  171.638084\n",
       "632        5    2048        2   62.923535  197.256679\n",
       "633        5    2048        3   72.110641  159.176387\n",
       "634        5    2048        4   61.400749  224.559143\n",
       "635        5    2048        5  100.450655  267.278314\n",
       "636        5    2048        6   83.274270  149.430076\n",
       "637        5    2048        7   76.937329  372.751855\n",
       "638        5    2048        8   72.540466  159.192980\n",
       "639        5    2048        9   85.574427  282.483434\n",
       "640        5    4096        0   75.242122  126.993030\n",
       "641        5    4096        1   65.811064  182.392661\n",
       "642        5    4096        2  107.916359  157.715097\n",
       "643        5    4096        3   55.902081  172.543293\n",
       "644        5    4096        4   75.237736  157.737794\n",
       "645        5    4096        5   68.440209  158.673893\n",
       "646        5    4096        6   89.811060  232.169025\n",
       "647        5    4096        7   70.876083  156.186867\n",
       "648        5    4096        8   76.415816  145.934886\n",
       "649        5    4096        9   85.283866  141.986165\n",
       "\n",
       "[650 rows x 5 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_df.to_csv('alt_fuels_hyperparameter_tuning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
